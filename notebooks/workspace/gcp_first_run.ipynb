{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First time Running BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af84cb3c-cb06-4b7b-a601-62c4c9edfeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCP BigQuery client initialized and verified.\n"
     ]
    }
   ],
   "source": [
    "# Agent's Thought Chain Reasoning Module served with Ollama\n",
    "# (c) 2024 Gaby AI Inc. - https://www.gaby.mimeus.com\n",
    "# Author: Mimi Phan\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(Path(__file__).resolve().parents[3]) if \"__file__\" in globals() else os.chdir(Path.cwd().root)\n",
    "\n",
    "import ollama\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env.local')\n",
    "\n",
    "OLLAMA_HOST_URL = os.getenv(\"OLLAMA_HOST_URL\", \"http://localhost:11434\")\n",
    "BASE_GUFF_LLM_MODEL = os.getenv(\"BASE_GUFF_LLM_MODEL\", \"hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q5_K_S\")\n",
    "\n",
    "class GabyBasement(ABC):\n",
    "    \"\"\" Prompt Base Constructor. \"\"\"\n",
    "\n",
    "    _client = None\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        try:\n",
    "            if cls._client is None:\n",
    "                cls._client = ollama.Client(\n",
    "                    base_url=OLLAMA_HOST_URL\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing GabyBasement: {e}\")\n",
    "        return super().__new__(cls, *args, **kwargs)\n",
    "\n",
    "    def __init_subclass__(cls, prompt: str = \"\", **kwargs):\n",
    "        super().__init_subclass__(**kwargs)\n",
    "        cls.prompt = getattr(cls, \"prompt\", prompt)  # donâ€™t overwrite if re-init\n",
    "        cls.name = cls.__qualname__\n",
    "\n",
    "    @property\n",
    "    def client(self):\n",
    "        return self._client\n",
    "\n",
    "    @property\n",
    "    def system_prompt(self):\n",
    "        return [{\"role\": \"system\", \"content\": self.prompt}]\n",
    "\n",
    "    def input_validator(self, **kwargs) -> None | str:\n",
    "        \"\"\" Validates the user's input is what the subclassed instance's run method expects. Seperate function to add different input types by overriding this function in subclass, otherwise defaults to current function. \"\"\"\n",
    "\n",
    "        if kwargs.get(\"inputs\", None) is None:\n",
    "            raise ValueError(\"Missing required 'inputs' parameter.\")\n",
    "\n",
    "        return kwargs.get(\"inputs\", None)\n",
    "\n",
    "    @abstractmethod\n",
    "    def post_process(self, response: str) -> str:\n",
    "        \"\"\" Post-processes the response from the LLM before returning to the user. \"\"\"\n",
    "        pass\n",
    "\n",
    "    def run(self, **kwargs) -> str:\n",
    "        \"\"\" Main method to execute the thought chain. \"\"\"\n",
    "\n",
    "        if not hasattr(self, \"client\") or self.client is None:\n",
    "            raise RuntimeError(\"Ollama client is not initialized.\"\n",
    "                               \" Ensure Ollama is running and OLLAMA_HOST_URL is correct.\")\n",
    "\n",
    "        print(f\"Running thought Chain: {self.name}\")\n",
    "\n",
    "        user_inputs = self.input_validator(**kwargs)\n",
    "\n",
    "        response = self.client.chat(\n",
    "            model=BASE_GUFF_LLM_MODEL,\n",
    "            messages=self.system_prompt + [{\"role\": \"user\", \"content\": user_inputs}],\n",
    "            stream=False,\n",
    "            options={\"max_tokens\": 500}\n",
    "        )\n",
    "        # TODO: ADD Post-processing later\n",
    "        return response.message.get('content', None)\n",
    "\n",
    "class BigQueryToolkit(ABC):\n",
    "    \"\"\" Gaby Agent's BigQuery Base Toolkit constructor. \"\"\"\n",
    "\n",
    "    bf: bigquery.Client | None = None\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        try:\n",
    "            if cls.bf is None:\n",
    "                if credentials_path := os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\", None):\n",
    "\n",
    "                    if not os.path.isfile(credentials_path):\n",
    "                        raise FileNotFoundError(f\"Credentials file not found at {credentials_path}\")\n",
    "\n",
    "                    credentials = service_account.Credentials.from_service_account_file(\n",
    "                        credentials_path\n",
    "                    )\n",
    "                    cls.bf = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "                else:\n",
    "                    raise EnvironmentError(\"GOOGLE_APPLICATION_CREDENTIALS environment variable not set.\")\n",
    "\n",
    "                print('GCP BigQuery client initialized and verified.')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing BigQueryToolkit: {e}\")\n",
    "\n",
    "        return super().__new__(cls, *args, **kwargs)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gb = BigQueryToolkit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_QUERY = \"SELECT * FROM `bigquery-public-data.samples.shakespeare` LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mimiphan/mimeus-app/backend/gaby/.venv/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sample = gb.bf.query(TEST_QUERY).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "word_count",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "corpus",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "corpus_date",
         "rawType": "Int64",
         "type": "integer"
        }
       ],
       "ref": "9f10b610-1d76-4cf8-babb-f2e039cc947d",
       "rows": [
        [
         "0",
         "LVII",
         "1",
         "sonnets",
         "0"
        ],
        [
         "1",
         "augurs",
         "1",
         "sonnets",
         "0"
        ],
        [
         "2",
         "dimm'd",
         "1",
         "sonnets",
         "0"
        ],
        [
         "3",
         "plagues",
         "1",
         "sonnets",
         "0"
        ],
        [
         "4",
         "treason",
         "1",
         "sonnets",
         "0"
        ],
        [
         "5",
         "surmise",
         "1",
         "sonnets",
         "0"
        ],
        [
         "6",
         "heed",
         "1",
         "sonnets",
         "0"
        ],
        [
         "7",
         "Unthrifty",
         "1",
         "sonnets",
         "0"
        ],
        [
         "8",
         "quality",
         "1",
         "sonnets",
         "0"
        ],
        [
         "9",
         "wherever",
         "1",
         "sonnets",
         "0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "      <th>corpus</th>\n",
       "      <th>corpus_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LVII</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>augurs</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dimm'd</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plagues</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>treason</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>surmise</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>heed</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unthrifty</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>quality</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wherever</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  word_count   corpus  corpus_date\n",
       "0       LVII           1  sonnets            0\n",
       "1     augurs           1  sonnets            0\n",
       "2     dimm'd           1  sonnets            0\n",
       "3    plagues           1  sonnets            0\n",
       "4    treason           1  sonnets            0\n",
       "5    surmise           1  sonnets            0\n",
       "6       heed           1  sonnets            0\n",
       "7  Unthrifty           1  sonnets            0\n",
       "8    quality           1  sonnets            0\n",
       "9   wherever           1  sonnets            0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gaby_agent.core.data_cleaner_chain import DirtyDataInspector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran checks on dataset with 10 rows and 4 fields for cleaning.\n"
     ]
    }
   ],
   "source": [
    "dt = DirtyDataInspector(sample, ['financial dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DirtyDataInspector(data=        word  word_count   corpus  corpus_date\n",
       "0       LVII           1  sonnets            0\n",
       "1     augurs           1  sonnets            0\n",
       "2     dimm'd           1  sonnets            0\n",
       "3    plagues           1  sonnets            0\n",
       "4    treason           1  sonnets            0\n",
       "5    surmise           1  sonnets            0\n",
       "6       heed           1  sonnets            0\n",
       "7  Unthrifty           1  sonnets            0\n",
       "8    quality           1  sonnets            0\n",
       "9   wherever           1  sonnets            0, description=['financial dataset'], fields=['word', 'word_count', 'corpus', 'corpus_date'], num_fields=4, num_rows=10, num_missing_values={'word': np.int64(0), 'word_count': np.int64(0), 'corpus': np.int64(0), 'corpus_date': np.int64(0)}, num_duplicates=np.int64(0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fields: 4\n",
      "Number of rows: 10\n",
      "Number of duplicates: 0\n",
      "Missing values per field:\n",
      "  - word: 0\n",
      "  - word_count: 0\n",
      "  - corpus: 0\n",
      "  - corpus_date: 0\n"
     ]
    }
   ],
   "source": [
    "print(dt.give_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DirtyDataInspector(data=        word  word_count   corpus  corpus_date\n",
       "0       LVII           1  sonnets            0\n",
       "1     augurs           1  sonnets            0\n",
       "2     dimm'd           1  sonnets            0\n",
       "3    plagues           1  sonnets            0\n",
       "4    treason           1  sonnets            0\n",
       "5    surmise           1  sonnets            0\n",
       "6       heed           1  sonnets            0\n",
       "7  Unthrifty           1  sonnets            0\n",
       "8    quality           1  sonnets            0\n",
       "9   wherever           1  sonnets            0, description=['financial dataset'], fields=['word', 'word_count', 'corpus', 'corpus_date'], num_fields=4, num_rows=10, num_missing_values={'word': np.int64(0), 'word_count': np.int64(0), 'corpus': np.int64(0), 'corpus_date': np.int64(0)}, num_duplicates=np.int64(0))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.api_core.page_iterator.HTTPIterator at 0x135dd91b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.bf.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gb.bf.list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shape': (10, 4), 'columns': {'word': dtype('O'), 'word_count': Int64Dtype(), 'corpus': dtype('O'), 'corpus_date': Int64Dtype()}, 'missing': {'word': 0, 'word_count': 0, 'corpus': 0, 'corpus_date': 0}, 'sample': [{'word': 'LVII', 'word_count': 1, 'corpus': 'sonnets', 'corpus_date': 0}, {'word': 'augurs', 'word_count': 1, 'corpus': 'sonnets', 'corpus_date': 0}, {'word': \"dimm'd\", 'word_count': 1, 'corpus': 'sonnets', 'corpus_date': 0}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summary = {\n",
    "    \"shape\": dt.data.shape,\n",
    "    \"columns\": dt.data.dtypes.to_dict(),\n",
    "    \"missing\": dt.data.isnull().sum().to_dict(),\n",
    "    \"sample\": dt.data.head(3).to_dict(orient=\"records\")\n",
    "}\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shape': (10, 4), 'columns': {'word': dtype('O'), 'word_count': Int64Dtype(), 'corpus': dtype('O'), 'corpus_date': Int64Dtype()}, 'missing': {'word': 0, 'word_count': 0, 'corpus': 0, 'corpus_date': 0}, 'sample': [{'word': 'LVII', 'word_count': 1, 'corpus': 'sonnets', 'corpus_date': 0}, {'word': 'augurs', 'word_count': 1, 'corpus': 'sonnets', 'corpus_date': 0}, {'word': \"dimm'd\", 'word_count': 1, 'corpus': 'sonnets', 'corpus_date': 0}]}\n"
     ]
    }
   ],
   "source": [
    "print(str(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ID = 'data-sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "CREATE OR REPLACE MODEL `{PROJECT_ID}.{DATASET_ID}.llama`\n",
    "OPTIONS(\n",
    "    model_type='remote',\n",
    "    remote_service_type='cloud_ai_large_language_model_v1',\n",
    "    endpoint='projects/{PROJECT_ID}/locations/us-central1/publishers/meta/models/llama2-7b-chat'\n",
    ");\"\"\"\n",
    "qq = gb.bf.query(query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
